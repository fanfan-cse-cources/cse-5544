{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db10d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from glob import glob\n",
    "from os.path import basename\n",
    "from os import cpu_count\n",
    "from itertools import islice\n",
    "from multiprocessing import Pool\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "def current_time(p: bool = True):\n",
    "    now = datetime.now()\n",
    "    if p:\n",
    "        time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    else:\n",
    "        time = now.strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "    return time\n",
    "\n",
    "\n",
    "def splitDict(d, num_of_cpus):\n",
    "    # split dict evenly by number of CPUs\n",
    "    \n",
    "    lists = []\n",
    "    n = len(d) // num_of_cpus\n",
    "    i = iter(d.items())\n",
    "    for x in range(num_of_cpus):\n",
    "        d = dict(islice(i, n))\n",
    "        lists.append(d)\n",
    "        \n",
    "    return lists\n",
    "\n",
    "\n",
    "def proc_df(users: dict):\n",
    "    # create sub-dataframe by given data\n",
    "    \n",
    "    praty_id = dict()\n",
    "    messages = pd.DataFrame(columns=['timestamp', 'unix-timestamp', 'hour', 'from', 'to', 'to_num', 'to_ext', 'location'])\n",
    "    \n",
    "    for uid in users:\n",
    "        for ts in users[uid]:\n",
    "            t = datetime.strptime(ts, \"%Y-%m-%d %H:%M:%S\")\n",
    "            to_ext = 0\n",
    "            \n",
    "            unix_time = int(time.mktime(t.timetuple()))\n",
    "            flipped = {}\n",
    "            for key, value in users[uid][ts].items():\n",
    "                if value not in flipped:\n",
    "                    flipped[value] = [key]\n",
    "                else:\n",
    "                    flipped[value].append(key)\n",
    "            \n",
    "            for loc in flipped:\n",
    "                if 'external' in flipped[loc]:\n",
    "                    to_ext = 1\n",
    "                    \n",
    "                messages.loc[len(messages.index)] = [ts, unix_time, t.hour, uid, flipped[loc], len(flipped[loc]), to_ext, loc]\n",
    "    \n",
    "    return messages\n",
    "\n",
    "\n",
    "def create_df(file: str):\n",
    "    logging.info(f\"[{file}] started at: {current_time()}\")\n",
    "    # create dataframe\n",
    "    \n",
    "    messages = pd.DataFrame(columns=['timestamp', 'unix-timestamp', 'hour','from', 'to', 'to_num', 'to_ext', 'location'])\n",
    "    fri = pd.read_csv(file, index_col=0)\n",
    "    users = dict()\n",
    "\n",
    "    for ts, row in fri.iterrows():\n",
    "        msg_from = str(row[0])\n",
    "        msg_to = row[1]\n",
    "        loc = row[2]\n",
    "\n",
    "        if msg_from not in users:\n",
    "            users[msg_from] = dict()\n",
    "        if ts not in users[msg_from]:\n",
    "            users[msg_from][ts] = dict()\n",
    "\n",
    "        users[msg_from][ts][msg_to] = loc\n",
    "        \n",
    "    # multiprocessing data entries\n",
    "    # num_of_cpus = 1\n",
    "    num_of_cpus = cpu_count() - 1\n",
    "    users_list = splitDict(users, num_of_cpus)\n",
    "    \n",
    "    with Pool(processes=num_of_cpus) as pool:\n",
    "        workers = list()\n",
    "        for user_item in users_list:\n",
    "            workers.append(pool.apply_async(proc_df, (user_item, )))\n",
    "    \n",
    "        for w in workers:\n",
    "            try:\n",
    "                messages = pd.concat([messages, w.get()])\n",
    "            except Exception as e:\n",
    "                logging.error(e)\n",
    "    \n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    \n",
    "    messages = messages.sort_values(by=['unix-timestamp'])\n",
    "    messages = messages.reset_index(drop=True)\n",
    "\n",
    "    # output dataframes to json\n",
    "    output_name = basename(file).replace(\"csv\", \"json\")\n",
    "    messages.to_csv(f\"./outputs/{basename(file)}\")\n",
    "    messages.to_json(f\"./outputs/{output_name}\")\n",
    "    \n",
    "    logging.info(f\"[{file}] completed at: {current_time()}\")\n",
    "    \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268667ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[./dataset/mc2_2015_data/comm-data-Fri.csv] started at: 2022-12-11 03:31:28\n",
      "INFO:root:[./dataset/mc2_2015_data/comm-data-Fri.csv] completed at: 2022-12-11 03:32:27\n",
      "INFO:root:[./dataset/mc2_2015_data/comm-data-Sat.csv] started at: 2022-12-11 03:32:27\n",
      "INFO:root:[./dataset/mc2_2015_data/comm-data-Sat.csv] completed at: 2022-12-11 03:34:14\n",
      "INFO:root:[./dataset/mc2_2015_data/comm-data-Sun.csv] started at: 2022-12-11 03:34:14\n"
     ]
    }
   ],
   "source": [
    "fri = create_df(\"./dataset/mc2_2015_data/comm-data-Fri.csv\")\n",
    "sat = create_df(\"./dataset/mc2_2015_data/comm-data-Sat.csv\")\n",
    "sun = create_df(\"./dataset/mc2_2015_data/comm-data-Sun.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833d9ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fri.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883db835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
